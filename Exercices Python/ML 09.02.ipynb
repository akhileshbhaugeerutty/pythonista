{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Akhilesh Bhaugeerutty & Magib Seck & Mouad Tai <b/>\n",
    "### <center> Exercices Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercices à rendre pour le 09/02:\n",
    "Exercice 3 page 92 & Exercice 2 page 102."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme auparavant, on charge les données dans un dataframe crédit: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A1_a</th>\n",
       "      <th>A1_b</th>\n",
       "      <th>A4_l</th>\n",
       "      <th>A4_u</th>\n",
       "      <th>...</th>\n",
       "      <th>A9_f</th>\n",
       "      <th>A9_t</th>\n",
       "      <th>A10_f</th>\n",
       "      <th>A10_t</th>\n",
       "      <th>A12_f</th>\n",
       "      <th>A12_t</th>\n",
       "      <th>A13_g</th>\n",
       "      <th>A13_p</th>\n",
       "      <th>A13_s</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>3.04</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A2     A3    A8  A11    A14    A15  A1_a  A1_b  A4_l  A4_u  ...  A9_f  \\\n",
       "0  30.83  0.000  1.25  1.0  202.0    0.0     0     1     0     1  ...     0   \n",
       "1  58.67  4.460  3.04  6.0   43.0  560.0     1     0     0     1  ...     0   \n",
       "2  24.50  0.500  1.50  0.0  280.0  824.0     1     0     0     1  ...     0   \n",
       "3  27.83  1.540  3.75  5.0  100.0    3.0     0     1     0     1  ...     0   \n",
       "4  20.17  5.625  1.71  0.0  120.0    0.0     0     1     0     1  ...     0   \n",
       "\n",
       "   A9_t  A10_f  A10_t  A12_f  A12_t  A13_g  A13_p  A13_s  A16  \n",
       "0     1      0      1      1      0      1      0      0    +  \n",
       "1     1      0      1      1      0      1      0      0    +  \n",
       "2     1      1      0      1      0      1      0      0    +  \n",
       "3     1      0      1      0      1      1      0      0    +  \n",
       "4     1      1      0      1      0      0      0      1    +  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "credit = pd.read_pickle(\"Downloads/credit.pkl\")\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable cible étant A16, on crée les échantillons de test et d'apprentissage ainsi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "variables = [x for x in credit.columns if x!='A16'] \n",
    "X = credit[variables] \n",
    "Y = credit['A16']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.25, random_state=2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons à présent entraîner les données dans un réseau de neurones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Network 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée un premier réseau de neurones, à deux couches cachées: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 8), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=2018, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn1 = MLPClassifier(hidden_layer_sizes=(10,8),activation='logistic', solver='lbfgs',random_state=2018, max_iter = 500)\n",
    "nn1.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.676829268292683"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test,nn1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7136886102403345"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score as auc\n",
    "auc(Y_test,nn1.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces chiffres paraissent plutôt faibles. On obtient en effet une précision inférieure à celle obtenue lors de la régression logistique normale, alors que ce modèle plus complexe devrait être capable de fournir une précision supérieure. <br>\n",
    "On scale les données pour voir si il y a un gain en précision:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8353658536585366\n",
      "AUC = 0.8653530377668309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "s = StandardScaler() \n",
    "s.fit(X) \n",
    "X_train_sc = s.transform(X_train) \n",
    "X_test_sc = s.transform(X_test)\n",
    "\n",
    "nn1.fit(X_train_sc,Y_train)\n",
    "print(\"Accuracy =\", accuracy_score(Y_test,nn1.predict(X_test_sc)))\n",
    "print(\"AUC =\", auc(Y_test,nn1.predict_proba(X_test_sc)[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient un net gain en précision et dans le score AUC, je vais ainsi utilser les données scalées à présent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Network 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour nn2, on ajoute une couche cachée ('hidden layer'), on en a donc 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 5, 8), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=2018, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn2 = MLPClassifier(hidden_layer_sizes=(10,5,8),activation='logistic', solver='lbfgs',random_state=2018, max_iter = 500)\n",
    "nn2.fit(X_train_sc,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8658536585365854\n",
      "AUC = 0.8265412748171369\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy =\", accuracy_score(Y_test,nn2.predict(X_test_sc)))\n",
    "print(\"AUC =\", auc(Y_test,nn2.predict_proba(X_test_sc)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un peu surprenant, nous avons gagné en accuracy, mais perdu sur le score AUC. Encore plus étrange, cette fois-ci, en prenant les données non normalisées, nous avons un meilleur AUC!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8292682926829268\n",
      "AUC = 0.9340200029855203\n"
     ]
    }
   ],
   "source": [
    "nn2.fit(X_train,Y_train)\n",
    "print(\"Accuracy =\", accuracy_score(Y_test,nn2.predict(X_test)))\n",
    "print(\"AUC =\", auc(Y_test,nn2.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le paramètre *'solver'* indiqque le critère d'optimisation que le neural network va utilier. Ici, ayant mis 'lbfgs', on a utilisé un critère de Quasi-Newton. On aurait pu utiliser une descente du gradiant, mais l'algorithme de Quasi-Newton est plus performant et converge plus rapidement quand on utilise des petits datasets. Si nous avions plus de données, il aurait fallu considérer les autres paramètres. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graphique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir entrainé les deux neural networks, on va maintenant tracer leur courbe ROC respectives, et ainsi les comparer. Il faut d'abord transformer la colonne à prédire (Y) en variable binaire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A1_a</th>\n",
       "      <th>A1_b</th>\n",
       "      <th>A4_l</th>\n",
       "      <th>A4_u</th>\n",
       "      <th>...</th>\n",
       "      <th>A9_t</th>\n",
       "      <th>A10_f</th>\n",
       "      <th>A10_t</th>\n",
       "      <th>A12_f</th>\n",
       "      <th>A12_t</th>\n",
       "      <th>A13_g</th>\n",
       "      <th>A13_p</th>\n",
       "      <th>A13_s</th>\n",
       "      <th>A16</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>3.04</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>+</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A2     A3    A8  A11    A14    A15  A1_a  A1_b  A4_l  A4_u  ...  A9_t  \\\n",
       "0  30.83  0.000  1.25  1.0  202.0    0.0     0     1     0     1  ...     1   \n",
       "1  58.67  4.460  3.04  6.0   43.0  560.0     1     0     0     1  ...     1   \n",
       "2  24.50  0.500  1.50  0.0  280.0  824.0     1     0     0     1  ...     1   \n",
       "3  27.83  1.540  3.75  5.0  100.0    3.0     0     1     0     1  ...     1   \n",
       "4  20.17  5.625  1.71  0.0  120.0    0.0     0     1     0     1  ...     1   \n",
       "\n",
       "   A10_f  A10_t  A12_f  A12_t  A13_g  A13_p  A13_s  A16  y  \n",
       "0      0      1      1      0      1      0      0    +  1  \n",
       "1      0      1      1      0      1      0      0    +  1  \n",
       "2      1      0      1      0      1      0      0    +  1  \n",
       "3      0      1      0      1      1      0      0    +  1  \n",
       "4      1      0      1      0      0      0      1    +  1  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit['y'] = np.where(credit['A16']=='+', '1', '0')\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditbis = credit.drop(columns = ['A16'])\n",
    "variables = [x for x in creditbis.columns if x!='y'] \n",
    "X = creditbis[variables] \n",
    "Y = creditbis['y']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.25, random_state=2018)\n",
    "Y_test = '1' <= Y_test #on remplace par des booléens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 5, 8), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=2018, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1 = MLPClassifier(hidden_layer_sizes=(10,8),activation='logistic', solver='lbfgs',random_state=2018, max_iter = 500)\n",
    "nn1.fit(X_train,Y_train)\n",
    "nn2 = MLPClassifier(hidden_layer_sizes=(10,5,8),activation='logistic', solver='lbfgs',random_state=2018, max_iter = 500)\n",
    "nn2.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(Y_test, nn1.predict_proba(X_test_sc)[:,1])\n",
    "fpr2, tpr2, threshold2 = roc_curve(Y_test, nn2.predict_proba(X_test)[:,1])\n",
    "\n",
    "auc(fpr,tpr)\n",
    "auc(fpr2,tpr2)\n",
    "\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"nn1, auc:\"+str(round(auc(fpr,tpr), 3))) \n",
    "plt.plot(fpr2,tpr2,label=\"nn2, auc:\"+str(round(auc(fpr2,tpr2), 3))) \n",
    "plt.plot([0,1],[0,1],color='cyan',linestyle='--') \n",
    "\n",
    "plt.ylabel(\"True Positive Rate\") \n",
    "plt.xlabel(\"False Positive Rate\") \n",
    "plt.legend(loc=4) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien que les deux courbes ROC ont l'air correctes, on voit que d'après la **'Règle du Nord-Ouest'**, le deuxième réseau de neurones est meilleur que le premier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La Règle du Nord-Ouest:**\n",
    "<br>\n",
    "\"Un point *(TFP(s), TVP(s))* de la courbe ROC correspondant à un classificateur donné est meilleur qu’un autre classificateur *(TFP(s'),TVP(s'))* s’il est au Nord-Ouest de celui-ci, *i.e*. qu’il aura un TVP plus élevé et un TFP plus faible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On charge les données dans un dataframe 'insurance', puis comme toujours, les divise en échantillons test/apprentissage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0   19  27.900         0  16884.92400           1         0          0   \n",
       "1   18  33.770         1   1725.55230           0         1          1   \n",
       "2   28  33.000         3   4449.46200           0         1          1   \n",
       "3   33  22.705         0  21984.47061           0         1          1   \n",
       "4   32  28.880         0   3866.85520           0         1          1   \n",
       "\n",
       "   smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0           1                 0                 0                 0   \n",
       "1           0                 0                 0                 1   \n",
       "2           0                 0                 0                 1   \n",
       "3           0                 0                 1                 0   \n",
       "4           0                 0                 1                 0   \n",
       "\n",
       "   region_southwest  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance = pd.read_pickle(\"Downloads/insurance.pkl\")\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [x for x in insurance.columns if x!='charges'] \n",
    "X = insurance[variables] \n",
    "Y = insurance['charges']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.20, random_state=2003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour s'assurer de l'homogéneité des résultats, on va scaler les données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StandardScaler() \n",
    "s.fit(X) \n",
    "X_train_sc = s.transform(X_train) \n",
    "X_test_sc = s.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va à présent lancer la phase d'apprentissage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural Network Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(10, 10), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "             random_state=2000, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor \n",
    "nn1 = MLPRegressor(hidden_layer_sizes=(10,10), activation='relu', solver='lbfgs',random_state=2000, max_iter = 1000)\n",
    "nn1.fit(X_train_sc,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2774.380043522321"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error as mae\n",
    "mae(Y_test,nn1.predict(X_test_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'erreur absolue est très élevée. Le modèle n'est pas adapté. Le $R^2$ quant à lui est plutôt correct. En effet, on obtient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8463565114631743"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y_test,nn1.predict(X_test_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche à présent à étudier les poids allant d'une couche cachée à une autre. <br>\n",
    "nn1.coefs_[0] correspond aux poids de l'input vers la première couche cachée, coefs_[1] sera de la première couche vers la deuxième couche. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nn1.coefs_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* du neurone 3 de la couche caché 1 à l’ensemble des neurones de la couche caché 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9520181 , 18.88299653, -3.17921347, -0.74164668, -0.51166957,\n",
       "       -0.77945734, -1.08036305, -0.0534209 , -2.2110309 , -0.45496379])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1.coefs_[1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* du neurone 3 de la couche cachée 1 au neurone 5 de la couche cachée 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5116695685895233"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1.coefs_[1][2][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde à présent les différents biais. On devrait avoir 10 biais pour la première et deuxième couche cachée. <br>\n",
    "Ici, on s'occupe du biais de la deuxième couche cachée:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.27783346, -24.95992679,  -4.10151137,  -5.50431172,\n",
       "        -2.01921756,  -4.85272264,  -4.96543669,  -1.52925254,\n",
       "       -13.85399939,  -3.16422055])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1.intercepts_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis, du biais du neurone 3 de la couche caché 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19.0866583063014"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1.intercepts_[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pose maintenant: <br>\n",
    "$N_i$ = number of input neurons <br>\n",
    "$N_o$ = number of output neurons <br>\n",
    "$N_s$ = number of samples in training data <br>\n",
    "${\\alpha}$ = an arbitrary scaling factor (usually 2-10).<br> \n",
    "$N_h = \\frac{N_s}{(\\alpha (N_i + N_o))}$ upper bound on the number of hidden neurons that won’t result in over-ﬁtting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on prend $\\alpha = 5$, on a donc, avec $N_i =$ nombre de variables, $N_o = 1$, (car régression), et $N_s = n_{train}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nh = 17.833333333333332\n"
     ]
    }
   ],
   "source": [
    "ns = len(X_train)\n",
    "a = 5\n",
    "ni = X.shape[1]\n",
    "no = 1\n",
    "nh = ns/(a*(ni+no))\n",
    "print('Nh =', nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il ne faut pas donc dépasser 18 neurones pour ne pas overfit les données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons à présent faire une Cross Validation afin d'obtenir les meilleurs paramètres possibles dans notre réseau de neurones. Notre critère d'optimisation est de maximiser le $R^2$. <br>\n",
    "Cette étape sera très lourde en calcul, nous allons faire au moins 81 calculs (chaque couple possible). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des couples: \n",
    "ss = np.arange(10,20)\n",
    "L = []\n",
    "for i in range(len(ss)):\n",
    "    for j in range(len(ss)):\n",
    "        L.append(tuple([ss[i],ss[j]]))\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "parameters = {'hidden_layer_sizes':L,\n",
    "              'activation':['relu'],\n",
    "              'solver':['lbfgs'],\n",
    "              'random_state':[2000],'max_iter':[1000]} #on prend pas 800\n",
    "nn = MLPRegressor() \n",
    "reg = GridSearchCV(nn, parameters, scoring='r2', cv = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=MLPRegressor(activation='relu', alpha=0.0001,\n",
       "                                    batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                                    early_stopping=False, epsilon=1e-08,\n",
       "                                    hidden_layer_sizes=(100,),\n",
       "                                    learning_rate='constant',\n",
       "                                    learning_rate_init=0.001, max_iter=200,\n",
       "                                    momentum=0.9, n_iter_no_change=10,\n",
       "                                    nesterovs_momentum=True, power_t=0.5,\n",
       "                                    random_stat...\n",
       "                                                (10, 13), (10, 14), (10, 15),\n",
       "                                                (10, 16), (10, 17), (10, 18),\n",
       "                                                (10, 19), (11, 10), (11, 11),\n",
       "                                                (11, 12), (11, 13), (11, 14),\n",
       "                                                (11, 15), (11, 16), (11, 17),\n",
       "                                                (11, 18), (11, 19), (12, 10),\n",
       "                                                (12, 11), (12, 12), (12, 13),\n",
       "                                                (12, 14), (12, 15), (12, 16),\n",
       "                                                (12, 17), (12, 18), (12, 19), ...],\n",
       "                         'max_iter': [1000], 'random_state': [2000],\n",
       "                         'solver': ['lbfgs']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X_train_sc,Y_train)\n",
    "#reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8239978074847466"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'hidden_layer_sizes': (11, 14),\n",
       " 'max_iter': 1000,\n",
       " 'random_state': 2000,\n",
       " 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est important de prendre les données avec scaling, car sans normalisation, on obtient 18 neurones dans la deuxième couche cachée. On aurait donc un sur-apprentissage (selon la partie théorique), car $N_h < 18$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(11, 14), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_iter=800, momentum=0.9,\n",
       "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "             random_state=2000, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnbest = MLPRegressor(hidden_layer_sizes=(11,14), activation='relu', solver='lbfgs',random_state=2000, max_iter = 800)\n",
    "nnbest.fit(X_train_sc,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2895.204588332535"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(Y_test,nnbest.predict(X_test_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8390377571042289"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y_test,nnbest.predict(X_test_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on prend des données non scalées, on obtient des résultats différents évidemment. La Validation Croisée n'a pas été très efficace, le $R^2$ n'est pas vraiment un excellent critère de maximisation. <br>\n",
    "De manière générale, le Réseau de Neurones a été moins efficace que le Support Vector Machine pour la Regression. Il faut donc se poser les bonnes questions, comme, a-t-on assez de données pour que les couches soient efficaces? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
